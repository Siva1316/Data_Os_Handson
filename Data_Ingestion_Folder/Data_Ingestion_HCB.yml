# Data Ingestion
version: v1  # v1
name: siva-data-ingestion-hcb
type: workflow
tags:
  - crm
description: Ingesting data in lakehouse
workflow:
  # schedule:
  #   cron: '00 20 * * *'
  #  # endOn: '2023-12-12T22:00:00Z'
  #   concurrencyPolicy: Forbid
  dag:
    - name: dg-customer-data
      # title: flatten Data Ingester
      # description: The job ingests Adobe flatten data from S3 into icebase zone
      spec:
        tags:
          - crm
        stack: flare:6.0
        compute: runnable-default
        stackSpec:
          driver:
            coreLimit: 2000m
            cores: 2
            memory: 3000m
          executor:
            coreLimit: 3000m
            cores: 2
            instances: 2
            memory: 4000m
          job:
            explain: true
            inputs:
              - name: Hotel_click_bookings
                dataset: dataos://ecpgdepot:public/hotel_click_bookings
                format: csv
                options:
                  driver: org.postgresql.Driver
            logLevel: INFO
            outputs:
              - name: final
                dataset: dataos://lakehouse:siva/hotel_click_booking?acl=rw
                format: Iceberg
                options:
                  saveMode: overwrite
                  iceberg:
                    properties:
                      write.format.default: parquet
                      write.metadata.compression-codec: gzip
            steps:
              - sequence:
                  - name: final
                    sql: >
                      SELECT
                        location_id,
                        geo_id,
                        booking_id,
                        advertiser_id,
                        campaign_id,
                        user_id,
                        ds
                      FROM Hotel_click_bookings;
